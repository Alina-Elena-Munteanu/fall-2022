using Optim, HTTP, GLM, LinearAlgebra, Random, Statistics, DataFrames, CSV, FreqTables

function allwrap()
    
    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    # question 1
    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    
    #Optim is function minimizer therefore we solve for -f(x)
    #optimize (the objective function, a strating value, an optimization algorithm)
    
    
    f(x) = -x[1]^4-10x[1]^3-2x[1]^2-3x[1]-2
    minusf(x) = x[1]^4+10x[1]^3+2x[1]^2+3x[1]+2
    startval = rand(1)   # random starting value
    result = optimize(minusf, startval, BFGS())
    #This function requires three inputs: the objective function, a starting value, and an optimization algorithm 
    println(result)

    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    # question 2
    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    
    url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2022/master/ProblemSets/PS1-julia-intro/nlsw88.csv"
    df = CSV.read(HTTP.get(url).body, DataFrame)
    X = [ones(size(df,1),1) df.age df.race.==1 df.collgrad.==1]
    y = df.married.==1

    function ols(beta, X, y)
        ssr = (y.-X*beta)'*(y.-X*beta)
        return ssr
    end

    #Optim requires closure 

    beta_hat_ols = optimize(b -> ols(b, X, y), rand(size(X,2)), LBFGS(), Optim.Options(g_tol=1e-6, iterations=100_000, show_trace=true))
    println(beta_hat_ols.minimizer)

    
    bols = inv(X'*X)*X'*y
    println(bols)
    df.white = df.race.==1
    bols_lm = lm(@formula(married ~ age + white + collgrad), df)
    println(bols_lm)

    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    # question 3
    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    function logit(alpha, X, y)

        D = exp.(X*alpha)./(1 .+ exp.(X*alpha))

        likelihood = -sum( (y.==1).*log.(D) .+ (y.==0).*log.(1 .- D) )

        return likelihood
    end

    alpha_hat_optim = optimize(a -> logit(a, X, y), rand(size(X,2)), LBFGS(), Optim.Options(g_tol=1e-6, iterations=100_000, show_trace=true))

    println(alpha_hat_optim.minimizer)

    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    # question 4
    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    # see Lecture 3 slides for example
    # Use te glm function to check your answer

    alpha_hat_glm = glm(@formula(married ~ age + white + collgrad), df, Binomial(), LogitLink())
    println(alpha_hat_glm)

    #The results are correct as I got julia> println(alpha_hat_optim.minimizer)
    #[0.7465534343250231, -0.021077756379598467, 0.955806533589654, -0.05597400404990658]
    #for both methods 

    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    # question 5
    #:::::::::::::::::::::::::::::::::::::::::::::::::::
    freqtable(df, :occupation) # note small number of obs in some occupations

    #Clean rows where occupation is missing. Also aggregate some of the occupation categories or else we won't be able to estimate our multinomial logit model
    
    df = dropmissing(df, :occupation)
    df[df.occupation.==8 ,:occupation] .=7
    df[df.occupation.==9 ,:occupation] .=7
    df[df.occupation.==10,:occupation] .= 7
    df[df.occupation.==11,:occupation] .= 7
    df[df.occupation.==12,:occupation] .= 7
    df[df.occupation.==13,:occupation] .= 7
    freqtable(df, :occupation) # problem solved

    X = [ones(size(df,1),1) df.age df.race.==1 df.collgrad.==1]
    y = df.occupation

    function mlogit(alpha, X, y)

        # your turn
        
        number_of_covariates=size(X,2) 
        vector_h=length(unique(y)) 
        number=length(y) 

        matrix=zeros(number, vector_h)

        for j=1:vector_h
            matrix[:,j] = y.==j
        end
        Alpha = [reshape(alpha,number_of_covariates,vector_h-1) zeros(number_of_covariates)]

        A=zeros(number,vector_h)
        B=zeros(number)

        for j=1:vector_h
            A[:,j]= exp.(X*Alpha[:,j])
            B .+=A[:,j]
        end

        D=A./repeat(B,1,vector_h)

        log_likelihood= -sum(matrix.*log.(D))

        return log_likelihood
    end

    alpha_empty = zeros(6*size(X,2))
    alpha_random = rand(6*size(X,2))
    alpha_good = [.1910213,-.0335262,.5963968,.4165052,-.1698368,-.0359784,1.30684,-.430997,.6894727,-.0104578,.5231634,-1.492475,-2.26748,-.0053001,1.391402,-.9849661,-1.398468,-.0142969,-.0176531,-1.495123,.2454891,-.0067267,-.5382892,-3.78975]
    alpha_ = alpha_good.*rand(size(alpha_good))
    println(size(alpha_good))
    alpha_hat_optim = optimize(a -> mlogit(a, X, y), alpha_, LBFGS(), Optim.Options(g_tol = 1e-5, iterations=100_000, show_trace=true))

end

allwrap()


